{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90319f2",
   "metadata": {},
   "source": [
    "## Primeros Pasos con el Framework de Agentes del SDK de Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a2af4",
   "metadata": {},
   "source": [
    "#### Instalando utilidades y dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install semantic-kernel==1.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d604c",
   "metadata": {},
   "source": [
    "#### Creando el Kernel y el Cliente AzureChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4561b6",
   "metadata": {},
   "outputs": [],
   "source": "# --- Importaciones Necesarias ---\nfrom semantic_kernel import Kernel # El orquestador principal.\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion # El conector para Azure OpenAI.\nfrom semantic_kernel.functions import KernelArguments # Para pasar argumentos a las funciones.\nimport os # Para leer variables de entorno.\nimport asyncio # Para operaciones asíncronas.\nimport time # Utilidad de tiempo.\nfrom dotenv import load_dotenv # Para cargar el archivo .env.\n\n# --- Inicialización del Kernel ---\n# Se crea la instancia del Kernel, el cerebro de la aplicación.\nkernel = Kernel()\n\n# Se carga el archivo .env que contiene las claves y configuraciones.\nload_dotenv()\n\n# --- Carga de Variables de Entorno ---\napi_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\ndeployment_name = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_MODEL\")\nendpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n\n# (Opcional) Imprime las variables para verificar que se cargaron correctamente.\nprint(f\"API Key: {api_key}\")\nprint(f\"Deployment Name: {deployment_name}\")\nprint(f\"Endpoint: {endpoint}\")\n\n# --- Conexión del Servicio de IA al Kernel ---\n# Se le da un alias o ID a nuestro servicio.\nservice_id = \"service1\"\n# Se añade el servicio de chat de Azure al Kernel para que pueda usar el modelo de IA.\nkernel.add_service(\n    AzureChatCompletion(service_id=service_id,\n                        api_key=api_key,\n                        deployment_name=deployment_name,\n                        endpoint = endpoint\n    )\n)"
  },
  {
   "cell_type": "markdown",
   "id": "2d376d05",
   "metadata": {},
   "source": [
    "#### Creando el Agente con el Cliente AzureChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31de34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la clase principal para crear un agente de chat.\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "# Importa clases para configurar cómo el agente ejecuta las funciones (herramientas).\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "# --- Configuración del Comportamiento del Agente ---\n",
    "# Se preparan los argumentos de ejecución para el agente.\n",
    "arguments = KernelArguments(\n",
    "        settings=PromptExecutionSettings(\n",
    "            # Esta es la configuración CLAVE para el comportamiento \"agente\".\n",
    "            # 'FunctionChoiceBehavior.Auto()' le dice al modelo que él mismo decida\n",
    "            # cuándo debe llamar a una función (herramienta) y que el Kernel\n",
    "            # la ejecute automáticamente. Esto habilita el \"function calling\" automático.\n",
    "            function_choice_behavior=FunctionChoiceBehavior.Auto(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# --- Creación del Agente ---\n",
    "# Se crea la instancia del agente de chat.\n",
    "agent = ChatCompletionAgent(\n",
    "  kernel=kernel, # Se le pasa el Kernel para que tenga acceso a los servicios de IA y plugins.\n",
    "  name=\"ChatCompletionAgent\", # Un nombre para identificar al agente.\n",
    "  instructions=\"Eres un asistente de IA muy útil\", # Instrucciones base sobre cómo debe comportarse.\n",
    "  arguments=arguments # Se le aplican las configuraciones de ejecución que definimos antes.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ed7e1",
   "metadata": {},
   "source": [
    "#### Enviando un mensaje simple a nuestro agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b741cc",
   "metadata": {},
   "outputs": [],
   "source": "# Se llama al agente con un único mensaje. Esto es una conversación de un solo turno, sin memoria.\nresponse = await agent.get_response(messages=\"Hola, ¿cómo estás?\")\n# Se imprime la respuesta del agente.\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "id": "f6caa50b",
   "metadata": {},
   "source": [
    "#### Viendo en Acción el Historial de Chat del Agente (Thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f1dee",
   "metadata": {},
   "outputs": [],
   "source": "# Importa la clase para manejar el historial de una conversación.\nfrom semantic_kernel.agents import ChatHistoryAgentThread\n\n# Se define el 'hilo' o 'thread'. Este objeto almacenará el historial de la conversación.\n# Es como abrir una ventana de chat persistente.\nthread = ChatHistoryAgentThread()\n\n# Se inicializa una variable para controlar el bucle del chat.\ncontinueChat = True\n\n# Comienza un bucle para chatear interactivamente con el agente.\nwhile continueChat:\n    # Pide al usuario que ingrese su mensaje.\n    user_input = input(\"Ingresa tu consulta: \")\n    # Si el usuario escribe 'exit', se termina la conversación.\n    if user_input.lower() == \"exit\":\n        continueChat = False\n        break\n    # Se llama al agente, pasándole tanto el nuevo mensaje como el objeto 'thread'.\n    # Al pasar el 'thread', el agente tendrá acceso a toda la conversación anterior para mantener el contexto.\n    response = await agent.get_response(messages=user_input, thread=thread)\n    # Se imprime la respuesta del agente en la consola.\n    print(response)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}