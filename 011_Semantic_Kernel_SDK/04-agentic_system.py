# -*- coding: utf-8 -*-

# ==============================================================================
# SECCI√ìN 1: IMPORTACIONES Y CONFIGURACI√ìN INICIAL
# ==============================================================================

# --- Importando las bibliotecas necesarias ---
from semantic_kernel import Kernel  # El "cerebro" u orquestador principal de Semantic Kernel.
import os  # Para interactuar con el sistema operativo, principalmente para leer variables de entorno.
import asyncio  # Para ejecutar c√≥digo de forma as√≠ncrona, necesario para las llamadas a la IA.
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion  # El conector espec√≠fico para el servicio de chat de Azure OpenAI.
from dotenv import load_dotenv  # Utilidad para cargar variables desde un archivo .env.
from semantic_kernel.planners import SequentialPlanner  # El "Director" que crear√° el plan paso a paso.
from typing import Annotated  # Para a√±adir metadatos (como descripciones) a los par√°metros de las funciones.
from semantic_kernel.functions.kernel_function_decorator import kernel_function  # El "decorador" que convierte una funci√≥n de Python en una herramienta para la IA.
from azure.ai.projects import AIProjectClient  # El cliente para interactuar con el servicio de Agentes de Azure AI.
from azure.identity import DefaultAzureCredential  # Para manejar la autenticaci√≥n con Azure.
from azure.ai.projects.models import BingGroundingTool  # La herramienta espec√≠fica para la b√∫squeda con Bing.

# --- Cargando las variables de entorno ---
# Carga las claves y configuraciones desde tu archivo .env para mantenerlas seguras.
load_dotenv()
azure_openai_key = os.getenv("AZURE_OPENAI_API_KEY")  # Tu clave secreta para la API de Azure OpenAI.
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")  # La URL de tu servicio de Azure OpenAI.
azure_openai_deployment_name = os.getenv("AZURE_OPENAI_CHAT_COMPLETION_MODEL")  # El nombre de tu modelo desplegado (ej. gpt-4).
ai_project_connection_string = os.getenv("AI_PROJECT_CONNECTION_STRING")  # La cadena de conexi√≥n para el servicio de Agentes de Azure AI.
bing_connection_name = os.getenv("BING_CONNECTION_NAME")  # El nombre de tu conexi√≥n de Bing preconfigurada en Azure.

# --- Creando el cliente de Azure AI ---
# Este objeto se usar√° para crear los agentes "trabajadores" o "especialistas".
project_client = AIProjectClient.from_connection_string(
        credential=DefaultAzureCredential(), # Usa tus credenciales de Azure para autenticarte.
        conn_str=ai_project_connection_string # Usa la cadena de conexi√≥n para apuntar al servicio correcto.
        )

# ==============================================================================
# SECCI√ìN 2: DEFINICI√ìN DEL PLUGIN DE AGENTES (LOS "ESPECIALISTAS")
# ==============================================================================

# Esta clase agrupa todas las funciones que actuar√°n como agentes especialistas.
class Agents:
    """
    La clase 'Agents' funciona como un contenedor para las herramientas que el Planificador podr√° usar.
    Cada m√©todo decorado con @kernel_function es una habilidad que el "Director" puede asignar.
    """

    # --- Agente Especialista 1: El Investigador Web ---
    @kernel_function(
        # La descripci√≥n es VITAL. El Planificador la lee para entender qu√© hace esta herramienta.
        description="Esta funci√≥n se usar√° para utilizar un agente de IA de Azure con capacidad de b√∫squeda web usando la API de B√∫squeda de Bing",
        # El nombre es c√≥mo el Planificador se referir√° a esta herramienta en el plan.
        name="WebSearchAgent"
    )
    def web_search_agent(
        self, # Par√°metro est√°ndar en los m√©todos de una clase.
        # 'Annotated' permite describir cada par√°metro. Esto tambi√©n ayuda al Planificador.
        query: Annotated[str, "La consulta del usuario para la cual se necesita obtener informaci√≥n contextual de la web"]
    ) -> Annotated[str, "La respuesta del agente de b√∫squeda web"]:
        """
        Esta funci√≥n completa es el 'Departamento de Investigaci√≥n'. Cuando se invoca,
        crea un agente de Azure AI desde cero, le da la herramienta de Bing, le asigna
        la tarea de buscar la 'query', y devuelve el resultado.
        """
        # Obtiene los detalles de la conexi√≥n de Bing preconfigurada en Azure.
        bing_connection = project_client.connections.get(connection_name=bing_connection_name)
        conn_id = bing_connection.id
        # Prepara la herramienta de Bing para d√°rsela al agente.
        bing = BingGroundingTool(connection_id=conn_id)
        
        # Crea un agente de Azure AI temporal y especializado. Su √∫nica misi√≥n es buscar.
        agent = project_client.agents.create_agent(
            model=azure_openai_deployment_name,
            name="bing-assistant", # Un nombre temporal para este agente.
            instructions="Eres un asistente √∫til",
            tools=bing.definitions, # La √∫nica herramienta que tendr√° es la b√∫squeda de Bing.
            headers={"x-ms-enable-preview": "true"},
        )
        # Cada agente necesita un "hilo" de conversaci√≥n para operar.
        thread = project_client.agents.create_thread()
        # Se a√±ade la consulta de b√∫squeda como el primer mensaje en la conversaci√≥n.
        message = project_client.agents.create_message(
                thread_id=thread.id,
                role="user",
                content=query,
            )
        # Se le ordena al agente que procese la conversaci√≥n y genere una respuesta.
        run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)
        # Se recupera la lista de mensajes, donde la respuesta del agente ser√° la m√°s reciente.
        messages = project_client.agents.list_messages(thread_id=thread.id)
        
        # Se imprime la respuesta para poder ver el progreso en la consola.
        print(f"\n--- [Respuesta del Investigador Web] ---\n{messages.data[0].content[0].text.value}\n---------------------------------------\n")
        
        # Se devuelve √∫nicamente el texto de la respuesta, que ser√° la entrada para el siguiente paso del plan.
        return messages.data[0].content[0].text.value
    
    # --- Agente Especialista 2: El Guionista de Noticias ---
    @kernel_function(
       description="Esta funci√≥n usar√° un agente de IA de Azure para preparar un guion para un reportero de noticias basado en informaci√≥n reciente para un tema espec√≠fico",
       name="NewsReporterAgent"
   )
    def news_reporter_agent(
        self,
        topic: Annotated[str, "El tema para el cual se ha obtenido la informaci√≥n/noticia m√°s reciente"],
        latest_news: Annotated[str,"La informaci√≥n m√°s reciente para un tema espec√≠fico"]
    ) -> Annotated[str, "la respuesta del NewsReporterAgent, que es el guion para el reportero"]:
        """
        Esta funci√≥n completa es el 'Departamento de Redacci√≥n'. Recibe la informaci√≥n
        investigada y su √∫nica misi√≥n es escribir un guion con un formato espec√≠fico.
        """
        # Crea un segundo agente de Azure AI, tambi√©n temporal y especializado. Su √∫nica misi√≥n es escribir.
        agent = project_client.agents.create_agent(
            model=azure_openai_deployment_name,
            name="news-reporter",
            # Las instrucciones son muy detalladas para asegurar que el resultado sea de alta calidad.
            instructions="""Eres un asistente √∫til destinado a preparar un guion para un reportero de noticias basado en la informaci√≥n m√°s reciente sobre un tema espec√≠fico, los cuales se te proporcionar√°n.
                El canal de noticias se llama MSinghTV y el reportero se llama John. Se te dar√° el tema y la informaci√≥n m√°s reciente para ese tema. Prepara un guion para el reportero John basado en esta informaci√≥n.""",
            headers={"x-ms-enable-preview": "true"}, # No tiene herramientas, solo instrucciones.
        )
        # Al igual que el otro agente, necesita su propio hilo de conversaci√≥n.
        thread = project_client.agents.create_thread()
        # Se le entrega la informaci√≥n (el tema y las noticias) en forma de un mensaje.
        message = project_client.agents.create_message(
                thread_id=thread.id,
                role="user",
                content=f"""El tema es {topic} y la informaci√≥n m√°s reciente es {latest_news}""",
            )
        # Se le ordena al agente que escriba el guion.
        run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)
        # Se recupera el guion final de la conversaci√≥n.
        messages = project_client.agents.list_messages(thread_id=thread.id)
        
        # Se imprime el guion final.
        print(f"\n--- [Guion del Reportero de Noticias] ---\n{messages.data[0].content[0].text.value}\n----------------------------------------\n")
            
        # Se devuelve el guion como el resultado final de esta funci√≥n.
        return messages.data[0].content[0].text.value

# ==============================================================================
# SECCI√ìN 3: INICIALIZACI√ìN DEL KERNEL Y EL PLANIFICADOR (EL "DIRECTOR")
# ==============================================================================

# Se crea la instancia principal del Kernel, el "cerebro" orquestador.
kernel = Kernel()
service_id = "default" # Un alias para nuestro servicio de IA.

# Se conecta el Kernel al modelo de lenguaje de Azure OpenAI. Ahora el Kernel tiene "poder de c√≥mputo".
kernel.add_service(
    AzureChatCompletion(service_id=service_id,
                        api_key=azure_openai_key,
                        deployment_name=azure_openai_deployment_name,
                        endpoint = azure_openai_endpoint
    )
)

# Se crea la instancia del Planificador. Este ser√° nuestro "M√°nager de Proyectos".
planner = SequentialPlanner(
    kernel, # Se le da acceso al Kernel para que pueda usar sus funciones y su IA.
    service_id # Se le indica qu√© servicio de IA debe usar para "pensar".
)

# Se a√±ade la clase 'Agents' como un plugin al Kernel.
# Este es el paso crucial donde el "Director" conoce a su "equipo de especialistas".
agents_plugin = kernel.add_plugin(Agents(), "Agents")


# ==============================================================================
# SECCI√ìN 4: EJECUCI√ìN DEL PLAN
# ==============================================================================

async def main():
    """Funci√≥n principal as√≠ncrona que orquesta todo el proceso."""
    
    # Se define el objetivo de alto nivel para el planificador.
    objetivo = f"preparar un guion de noticias para John sobre las √∫ltimas noticias de la India?"
    print(f"üéØ Objetivo: {objetivo}\n")

    # --- Fase de Planificaci√≥n ---
    print("üß†  El Director est√° pensando y creando un plan...")
    # Se le pide al planificador que cree un plan para alcanzar el objetivo.
    # En este momento, el planificador est√° llamando a la IA para que razone.
    sequential_plan = await planner.create_plan(objetivo)

    # Se imprime el plan que el planificador ha decidido seguir.
    print("\nüìù Los pasos del plan son:")
    for step in sequential_plan._steps:
        print(
            f"  - {step.description.replace('.', '') if step.description else 'Sin descripci√≥n'} usando la herramienta '{step.metadata.fully_qualified_name}' con los par√°metros: {step.parameters}"
        )

    # --- Fase de Ejecuci√≥n ---
    print("\nüöÄ Ejecutando el plan...")
    # Se invoca el plan. El Kernel ejecutar√° cada paso en secuencia,
    # pasando autom√°ticamente la salida de un paso como la entrada del siguiente.
    result = await sequential_plan.invoke(kernel)

    print("\n‚úÖ Ejecuci√≥n finalizada.")
    # El resultado final (el guion) ya se imprime dentro de la funci√≥n 'news_reporter_agent'.
    # La variable 'result' contiene el mismo valor.

# Punto de entrada est√°ndar para un script de Python.
if __name__ == "__main__":
    # Se ejecuta la funci√≥n principal 'main' usando el gestor de eventos de asyncio.
    asyncio.run(main())